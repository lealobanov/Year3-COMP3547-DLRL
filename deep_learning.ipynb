{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cssg28_DL.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdpvQAP6Iomk"
      },
      "source": [
        "#Generating Pegasus with DCGAN\n",
        "\n",
        "#Citations to relevant components of code are referenced throughout the notebook in single line comments"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MK1Jl7nkLnPA"
      },
      "source": [
        "#Import necessary libraries\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import random\n",
        "%matplotlib inline\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data\n",
        "import torchvision.utils as vutils\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "# Ignore excessive warnings\n",
        "import logging\n",
        "logging.propagate = False \n",
        "logging.getLogger().setLevel(logging.ERROR)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhhBTqyRgqK3"
      },
      "source": [
        "Set hyperparameter values during initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpLWH83LalSv"
      },
      "source": [
        "# Number of workers for dataloader\n",
        "workers = 2\n",
        "batch_size = 128\n",
        "# Training image size - CIFAR-10 is 32x32 by default; however, STL-10 was resized and downscaled to these dimensions using a Transformer\n",
        "image_size = 32\n",
        "# Number of channels in training images - 3 when using RGB, 1 for grayscale\n",
        "nc = 3\n",
        "# Size of z latent vector \n",
        "nz = 100\n",
        "# Size of feature maps in generator, descriminator\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "# Number of training epochs - observed that with the current hyperparameters, best pegasus are generated between epochs 250-450, before DCGAN begins producing images that too closely resemble individual class labels\n",
        "epochs = 600\n",
        "# Learning rate for optimizers - deemed optimal at 0.0003 after many experimental trial runs (initially tested on .0002 as proposed by Radford et al. in the DCGAN paper)\n",
        "lr = 0.0003\n",
        "# Beta1 hyperparameter for Adam optimizers\n",
        "beta1 = 0.5\n",
        "# Number of GPUs to utilize \n",
        "ngpu = 1 #Passing 0 will default to CPU\n",
        "\n",
        "#Referenced for tuning and GAN optimizations: https://github.com/soumith/ganhacks"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WC22A-MSa9xc"
      },
      "source": [
        "Data preparation: CIFAR-10 and STL-10 datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acxwviQveXY5"
      },
      "source": [
        "def STL_preprocessing():\n",
        "  \n",
        "    transforms_ = transforms.Compose([\n",
        "      #Scale STL-10 down from 96x96 to 32x32 for compatibility with CIFAR-10\n",
        "      transforms.Resize(32),\n",
        "      transforms.CenterCrop(32),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "  ])\n",
        "  \n",
        "    dataset = torchvision.datasets.STL10(root=\"./data\",\n",
        "                                          split=\"train\",\n",
        "                                          download=True,\n",
        "                                          transform=transforms_)\n",
        "    \n",
        "    #Specify desired class labels: in generating a pegasus, a combination of horse, bird, and airplane was found optimal\n",
        "\n",
        "    #Initialize arrays and counters for sorting data in buckets\n",
        "    num_birds = 0\n",
        "    num_planes = 0\n",
        "    num_horses = 0\n",
        "\n",
        "    dataset_total = []\n",
        "\n",
        "    #Class labels - deer were also considered but ultimately not utilized in the final implementation\n",
        "    plane_label = 0\n",
        "    bird_label = 1\n",
        "    horse_label = 6\n",
        "\n",
        "    #Iterate and sort in corresponding bucket\n",
        "    for i in dataset:\n",
        "        #All of STL-10 labeled data is utilized for training; only 500 per class\n",
        "        if i[1] == plane_label and num_planes < 500:\n",
        "            dataset_total.append(i)\n",
        "            num_planes +=1\n",
        "        if i[1] == horse_label and num_horses < 500:\n",
        "            dataset_total.append(i)\n",
        "            #For experimentation when using STL only consider doubling up on horses\n",
        "            #dataset_total.append(i)\n",
        "            num_horses +=1\n",
        "        if i[1] == bird_label and num_birds < 500:\n",
        "            dataset_total.append(i)\n",
        "            num_birds +=1\n",
        "\n",
        "    #Check data counts for each class\n",
        "    print(\"Num planes (STL-10) \", num_planes)   \n",
        "    print(\"Num horses (STL-10) \", num_horses)  \n",
        "    print(\"Num birds (STL-10) \", num_birds)  \n",
        "    print(\"Total (STL-10) \", len(dataset_total))\n",
        "    print(\"\")   \n",
        "\n",
        "    return dataset_total"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYjFkwi1f0GR"
      },
      "source": [
        "def CIFAR_preprocessing(STL_cleaned):\n",
        "  \n",
        "    dataset_train = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "\n",
        "    dataset_test = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=torchvision.transforms.Compose([\n",
        "        torchvision.transforms.ToTensor()\n",
        "    ]))\n",
        "    \n",
        "    #Merge training and test sets s.t. more data available for pegasus generation\n",
        "    cifar_dataset = torch.utils.data.ConcatDataset((dataset_train, dataset_test))\n",
        "\n",
        "    num_planes = 0\n",
        "    num_birds = 0\n",
        "    num_horses = 0 \n",
        "\n",
        "    #Initialize arrays and counters for sorting data in buckets\n",
        "    ##So far the dataset contains the cleaned STL-10 images\n",
        "    dataset_total = STL_cleaned\n",
        "\n",
        "    #Class labels - deer were also considered but ultimately not utilized in the final implementation\n",
        "    plane_label = 0\n",
        "    bird_label = 2\n",
        "    horse_label = 7\n",
        "\n",
        "    #Iterate through CIFAR and sort in corresponding bucket\n",
        "    for i in cifar_dataset:\n",
        "        #Set relevant quantities for each class to define its proportion of the total dataset\n",
        "        if i[1] == plane_label and num_planes < 1800:\n",
        "            dataset_total.append(i)\n",
        "            num_planes +=1\n",
        "        if i[1] == horse_label and num_horses < 5000:\n",
        "            #Try doubling up on horse to maintain horse structure \n",
        "            dataset_total.append(i)\n",
        "            #dataset_total.append(i)\n",
        "            num_horses +=1\n",
        "        if i[1] == bird_label and num_birds < 900:\n",
        "            dataset_total.append(i)\n",
        "            num_birds +=1\n",
        "\n",
        "    #Check data counts for each class\n",
        "    print(\"Num planes (STL-10 and CIFAR-10 merged) \", num_planes)   \n",
        "    print(\"Num horses (STL-10 and CIFAR-10 merged) \", num_horses)  \n",
        "    print(\"Num birds (STL-10 and CIFAR-10 merged) \", num_birds)  \n",
        "    print(\"Total (STL-10 and CIFAR-10 merged) \", len(dataset_total))\n",
        "    print(\"\")\n",
        "\n",
        "    return dataset_total"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KchWCW9dgV3b"
      },
      "source": [
        "#Additional data cleaning and processing functions which were used during experimentation \n",
        "\n",
        "#Transform images to grayscale - experimented as possible solution to force whiteness of the pegasus\n",
        "def grayscale_transform():\n",
        "  tograyscale = transforms.Compose([\n",
        "    torchvision.transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "  return tograyscale\n",
        "\n",
        "#Upscale CIFAR-10 to 96x96 to train alongsize full resolution STL-10; similar transforms were used when testing on 64x64 CIFAR-10 and STL-10 combined \n",
        "def CIFAR_to96():\n",
        "  cifar_transforms = transforms.Compose([\n",
        "    transforms.Resize(96),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
        "])\n",
        "  return cifar_transforms\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qnjh12UbNFpV"
      },
      "source": [
        "DCGAN: Define Generator and Discriminator\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGbLY6X-NH4O"
      },
      "source": [
        "#Implementation follows PyTorch documentation DCGAN tutorial: https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzMNCRO8cHXr"
      },
      "source": [
        "#Generator\n",
        "##By default the DCGAN implementation outlined in the Pytorch documentation operators on 64x64 images; the structure was modified to output 32x32 images from the Generator and takes 32x32 input into the Discriminator, so as to work with CIFAR-10: https://wandb.ai/sairam6087/dcgan/reports/DCGAN-on-CIFAR-10--Vmlldzo5NjMyOQ\n",
        "\n",
        "#G and D operating on 32x32 input/output\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8), #(ngf*8) x 4 x 4\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),  #(ngf*8) x 4 x 4\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True), #(ngf*4) x 8 x 8\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False), \n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True), #(ngf*2) x 16 x 16\n",
        "            nn.ConvTranspose2d( ngf * 2, nc, 4, 2, 1, bias=False), \n",
        "            nn.Tanh() #3x32x32\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L4pRT8scJ0G"
      },
      "source": [
        "#Discriminator\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential( #3x32x32\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            #Using Leaky ReLU activation function in discriminator\n",
        "            nn.LeakyReLU(0.2, inplace=True), #(ndf) x 16 x 16\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True), #(ndf*2) x 8 x 8\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True), #(ndf*4) x 4 x 4\n",
        "            nn.Conv2d(ndf * 4, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oJ-FGNZjsFo"
      },
      "source": [
        "#Initialize weights randomly from a normal distribution\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0EO3CDtc7mc"
      },
      "source": [
        "Define the training function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_ErtDCHc-kv"
      },
      "source": [
        "#https://wandb.ai/sairam6087/dcgan/reports/DCGAN-on-CIFAR-10--Vmlldzo5NjMyOQ - furthers the DCGAN Pytorch implementation by adding label smoothing\n",
        "def train(gen, disc, device, dataloader, optimizerG, optimizerD, criterion, epoch, iters):\n",
        "  gen.train()\n",
        "  disc.train()\n",
        "  img_list = []\n",
        "  fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "  # Establish convention for real and fake labels during training (with label smoothing)\n",
        "  real_label = 0.9\n",
        "  fake_label = 0.1\n",
        "  for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "      # Update Discriminator\n",
        "\n",
        "      # Train with all-real batch\n",
        "      disc.zero_grad()\n",
        "      # Format batch\n",
        "      real_cpu = data[0].to(device)\n",
        "      b_size = real_cpu.size(0)\n",
        "      label = torch.full((b_size,), real_label, device=device)\n",
        "      # Forward pass real batch through D\n",
        "      output = disc(real_cpu).view(-1)\n",
        "      # Calculate loss on all-real batch\n",
        "      errD_real = criterion(output, label)\n",
        "      # Calculate gradients for D in backward pass\n",
        "      errD_real.backward()\n",
        "      D_x = output.mean().item()\n",
        "\n",
        "      #Train with all-fake batch\n",
        "      # Generate batch of latent vectors\n",
        "      noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "      # Generate fake image batch with G\n",
        "      fake = gen(noise)\n",
        "      label.fill_(fake_label)\n",
        "      # Classify all fake batch with D\n",
        "      output = disc(fake.detach()).view(-1)\n",
        "      # Calculate D loss on the all-fake batch\n",
        "      errD_fake = criterion(output, label)\n",
        "      # Calculate the gradients for this batch\n",
        "      errD_fake.backward()\n",
        "      D_G_z1 = output.mean().item()\n",
        "      # Add the gradients from the all-real and all-fake batches\n",
        "      errD = errD_real + errD_fake\n",
        "      # Update D\n",
        "      optimizerD.step()\n",
        "\n",
        "      # Update Generator\n",
        "      gen.zero_grad()\n",
        "      label.fill_(real_label)\n",
        "      # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "      output = disc(fake).view(-1)\n",
        "      # Calculate G's loss based on this output\n",
        "      errG = criterion(output, label)\n",
        "      # Calculate gradients for G\n",
        "      errG.backward()\n",
        "      D_G_z2 = output.mean().item()\n",
        "      # Update G\n",
        "      optimizerG.step()  \n",
        "\n",
        "      #Output generator images at each epoch and save best pegasus output\n",
        "      if (iters % 500 == 0) or ((epoch == epochs-1) and (i == len(dataloader)-1)):\n",
        "          print(\"Current epoch \", epoch)  \n",
        "          print(\"\")\n",
        "          #Print training stats\n",
        "          print(\"Generator loss: \", errG.item())\n",
        "          print(\"Discriminator loss: \", errD.item())\n",
        "          print(\"\")\n",
        "          with torch.no_grad():\n",
        "              fake = gen(fixed_noise).detach().cpu()\n",
        "          plt.rcParams['figure.dpi'] = 175\n",
        "          plt.grid(False)\n",
        "          plt.imshow(torchvision.utils.make_grid(fake).cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
        "          plt.show()\n",
        "\n",
        "          #To improve training speed, training and candidate image generation was carried out using wandb.ai: https://wandb.ai/\n",
        "      iters += 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1UBl0PJjY-f"
      },
      "source": [
        "**Main training loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LnA9fJedG6G"
      },
      "source": [
        "def main():\n",
        "    use_cuda = not False and torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "    \n",
        "    #Set seeds\n",
        "    manualSeed = 42\n",
        "    random.seed(manualSeed)\n",
        "    torch.manual_seed(manualSeed)\n",
        "\n",
        "    #Python random seed\n",
        "    random.seed(manualSeed)\n",
        "    #Pytorch random seed       \n",
        "    torch.manual_seed(manualSeed) \n",
        "    #Numpy random seed\n",
        "    np.random.seed(manualSeed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    #Load the dataset\n",
        "    print(\"Loading the dataset...\")\n",
        "    print(\"\")\n",
        "    \n",
        "    #First pre-process STL-10\n",
        "    prepared_STL = STL_preprocessing()\n",
        "\n",
        "    #Next process CIFAR-10\n",
        "    dataset_merged = CIFAR_preprocessing(prepared_STL)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(dataset_merged, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "    \n",
        "    # Create the generator\n",
        "    netG = Generator(ngpu).to(device)\n",
        "\n",
        "    # Handle multi-gpu if desired\n",
        "    if (device.type == 'cuda') and (ngpu > 1):\n",
        "        netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "    # Apply the weights_init function to randomly initialize all weights\n",
        "    #  to mean=0, stdev=0.2.\n",
        "    netG.apply(weights_init)\n",
        "\n",
        "    # Create the Discriminator\n",
        "    netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "    # Handle multi-gpu if desired\n",
        "    if (device.type == 'cuda') and (ngpu > 1):\n",
        "        netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "    # Apply the weights_init function to randomly initialize all weights\n",
        "    #  to mean=0, stdev=0.2.\n",
        "    netD.apply(weights_init)\n",
        "\n",
        "    # Initialize BCELoss function\n",
        "    criterion = nn.BCELoss()\n",
        "\n",
        "    # Setup Adam optimizers for both G and D\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "    \n",
        "    iters = 0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(netG, netD, device, trainloader, optimizerG, optimizerD, criterion, epoch, iters)\n",
        "        "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvPXYcujdtS8"
      },
      "source": [
        "Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPKdfBSNduVd"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOXYT2l8o8aV"
      },
      "source": [
        "Dataset - Google Drive Integrations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akSbYvRzpDph"
      },
      "source": [
        "# optional Google drive integration - this will allow you to save and resume training, and may speed up redownloading the dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}